{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_501648/2612893350.py:11: RuntimeWarning: overflow encountered in true_divide\n",
      "  gradient = np.dot(X.T, (y_pred - y)) / m + w / sigma2  # L2 regularization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'gamma': 0.001, 'sigma2': 0.01}\n",
      "Dev Precision: 1.0000\n",
      "Dev Recall: 0.4010\n",
      "Dev F1 Score: 0.5724\n",
      "Dev Accuracy: 0.4010\n",
      "Test Precision: 0.7207\n",
      "Test Recall: 0.5923\n",
      "Test F1 Score: 0.6502\n",
      "Test Accuracy: 0.6916\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def sigmoid(z):\n",
    "    z = np.clip(z, -500, 500)  # Clip to prevent overflow in the exponential calculation\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def compute_gradient(X, y, w, sigma2):\n",
    "    m = X.shape[0]\n",
    "    y_pred = sigmoid(np.dot(X, w)) * 2 - 1  # Transform sigmoid output to -1 and +1\n",
    "    gradient = np.dot(X.T, (y_pred - y)) / m + w / sigma2  # L2 regularization\n",
    "    return gradient\n",
    "\n",
    "def logistic_regression_SGD(X_train, y_train, learning_rate, epochs, sigma2, batch_size=32):\n",
    "    w = np.zeros(X_train.shape[1])  # Initialize weights to zeros\n",
    "    num_samples = X_train.shape[0]\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        indices = np.random.permutation(num_samples)\n",
    "        X_train_shuffled = X_train[indices]\n",
    "        y_train_shuffled = y_train[indices]\n",
    "        \n",
    "        for start in range(0, num_samples, batch_size):\n",
    "            end = min(start + batch_size, num_samples)\n",
    "            X_batch = X_train_shuffled[start:end]\n",
    "            y_batch = y_train_shuffled[start:end]\n",
    "            \n",
    "            gradient = compute_gradient(X_batch, y_batch, w, sigma2)\n",
    "            w -= learning_rate * gradient\n",
    "\n",
    "        learning_rate /= (1 + epoch)  # Decaying learning rate each epoch\n",
    "\n",
    "    return w\n",
    "\n",
    "def predict(X, weights):\n",
    "    z = np.dot(X, weights)\n",
    "    return np.where(sigmoid(z) >= 0.5, 1, -1)\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    true_positives = np.sum((y_pred == 1) & (y_true == 1))\n",
    "    false_positives = np.sum((y_pred == 1) & (y_true == -1))\n",
    "    false_negatives = np.sum((y_pred == -1) & (y_true == 1))\n",
    "    precision = true_positives / (true_positives + false_positives) if true_positives + false_positives > 0 else 0\n",
    "    recall = true_positives / (true_positives + false_negatives) if true_positives + false_negatives > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if precision + recall > 0 else 0\n",
    "    return precision, recall, f1\n",
    "\n",
    "def calculate_accuracy(y_true, y_pred):\n",
    "    correct_predictions = np.sum(y_true == y_pred)\n",
    "    total_predictions = len(y_true)\n",
    "    return correct_predictions / total_predictions\n",
    "\n",
    "def perform_cross_validation(X, y, k, learning_rates, sigma2_values, epochs, batch_size):\n",
    "    num_samples = len(y)\n",
    "    folds = k_fold_split(num_samples, k)\n",
    "    best_f1 = -np.inf\n",
    "    best_params = {}\n",
    "\n",
    "    for gamma in learning_rates:\n",
    "        for sigma2 in sigma2_values:\n",
    "            f1_scores = []\n",
    "\n",
    "            for i in range(k):\n",
    "                test_idx = folds[i]\n",
    "                train_idx = np.hstack([folds[j] for j in range(k) if j != i])\n",
    "\n",
    "                X_train, X_valid = X[train_idx], X[test_idx]\n",
    "                y_train, y_valid = y[train_idx], y[test_idx]\n",
    "                \n",
    "                weights = logistic_regression_SGD(X_train, y_train, gamma, epochs, sigma2, batch_size)\n",
    "                y_pred_valid = predict(X_valid, weights)\n",
    "                _, _, f1 = calculate_metrics(y_valid, y_pred_valid)\n",
    "                \n",
    "                f1_scores.append(f1)\n",
    "\n",
    "            avg_f1 = np.mean(f1_scores)\n",
    "            if avg_f1 > best_f1:\n",
    "                best_f1 = avg_f1\n",
    "                best_params = {'gamma': gamma, 'sigma2': sigma2}\n",
    "\n",
    "    return best_params\n",
    "\n",
    "def k_fold_split(num_samples, k=5):\n",
    "    indices = np.arange(num_samples)\n",
    "    np.random.shuffle(indices)\n",
    "    fold_sizes = np.full(k, num_samples // k, dtype=int)\n",
    "    fold_sizes[:num_samples % k] += 1\n",
    "    current = 0\n",
    "    folds = []\n",
    "    for fold_size in fold_sizes:\n",
    "        start, stop = current, current + fold_size\n",
    "        folds.append(indices[start:stop])\n",
    "        current = stop\n",
    "    return folds\n",
    "\n",
    "# Load datasets\n",
    "full_train_data = pd.read_csv('/home/u1472278/ML/Project/project_data/new.tfidf.train.csv')\n",
    "dev_data = pd.read_csv('/home/u1472278/ML/Project/project_data/data/tfidf/tfidf.eval.anon.csv')\n",
    "test_data = pd.read_csv('/home/u1472278/ML/Project/project_data/new.tfidf.test.csv')\n",
    "\n",
    "X_train_full = full_train_data.iloc[:, 1:].values\n",
    "y_train_full = full_train_data.iloc[:, 0].values\n",
    "X_dev = dev_data.iloc[:, 1:].values\n",
    "y_dev = dev_data.iloc[:, 0].values\n",
    "X_test = test_data.iloc[:, 1:].values\n",
    "y_test = test_data.iloc[:, 0].values\n",
    "\n",
    "# Hyperparameters and training configuration\n",
    "learning_rates = [0.1, 0.01, 0.001]\n",
    "sigma2_values = [0.01, 0.1, 1]\n",
    "epochs = 100\n",
    "batch_size = 64\n",
    "k = 5  # Number of folds\n",
    "\n",
    "# Perform cross-validation to find the best hyperparameters\n",
    "best_params = perform_cross_validation(X_train_full, y_train_full, k, learning_rates, sigma2_values, epochs, batch_size)\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Train on the full training data using the best hyperparameters\n",
    "final_weights = logistic_regression_SGD(X_train_full, y_train_full, best_params['gamma'], epochs, best_params['sigma2'], batch_size)\n",
    "\n",
    "# Predict and evaluate on the dev set\n",
    "y_pred_dev = predict(X_dev, final_weights)\n",
    "dev_precision, dev_recall, dev_f1 = calculate_metrics(y_dev, y_pred_dev)\n",
    "dev_accuracy = calculate_accuracy(y_dev, y_pred_dev)\n",
    "\n",
    "predicted_labels_int = y_pred_dev.astype(int)\n",
    "predicted_labels_df = pd.DataFrame(predicted_labels_int, columns=['label'])\n",
    "eval_ids = pd.read_csv(\"data/eval.ids\", header=None, names=['example_id'])\n",
    "\n",
    "submission_df = pd.concat([eval_ids['example_id'], predicted_labels_df], axis=1)\n",
    "\n",
    "# Save the concatenated DataFrame to a CSV file\n",
    "submission_df.to_csv('submission_lr_tfidf.csv', index=False)\n",
    "print(f\"Dev Precision: {dev_precision:.4f}\")\n",
    "print(f\"Dev Recall: {dev_recall:.4f}\")\n",
    "print(f\"Dev F1 Score: {dev_f1:.4f}\")\n",
    "print(f\"Dev Accuracy: {dev_accuracy:.4f}\")\n",
    "\n",
    "# Predict and evaluate on the test set\n",
    "y_pred_test = predict(X_test, final_weights)\n",
    "test_precision, test_recall, test_f1 = calculate_metrics(y_test, y_pred_test)\n",
    "test_accuracy = calculate_accuracy(y_test, y_pred_test)\n",
    "print(f\"Test Precision: {test_precision:.4f}\")\n",
    "print(f\"Test Recall: {test_recall:.4f}\")\n",
    "print(f\"Test F1 Score: {test_f1:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
